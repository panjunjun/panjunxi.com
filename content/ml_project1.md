Title: 如何将机器学习工程化
Slug: ml-project
Date: 2017-07-09 08:57
Category: 工程
Tags: 机器学习
Author: 潘俊xi
Summary: 将手中的试验品变成一个产品


随着机器学习技术的大热, 学习、制作一个算法的模型变得越来越快、简单, 但是如何将手中的模型应用到一个产品上去, 是需要从更大的角度做一些取舍。
做项目、架构、产品之类的事情, 要管理三个基本要素: 需求、资源、时间。 这三个要素互相作用, 互相平衡。
需求太多太复杂, 加人力、硬件、管理资源, 需要更多的时间。
资源有限, 时间紧迫, 那需要砍掉不重要的需求。
如果只是一个POC, 那么成熟的、前沿的、炫酷的都可以使用, 但是一旦要涉及到满足业务需求、产品的实现、能带来实际的收入, 则需要全方位的考虑这个问题。
本篇以我在宏原的做BI产品E棱镜的经验, 来聊一聊如何将机器学习工程化。
(不涉及任何代码)<br>

一、先介绍一下和机器学习业务需求:

1. 能为客户提供根据市场的大致情况(并非给定一个新商品, 看如何定价)推导出的商品价格
2. 能从同类市场当中快速的查询天猫、淘宝中, 用户自己和同行的店铺信息、商品信息的数据

1.1. 价格推导就是一个回归模型, 涉及的特征有:

+ 商品已上架日期
+ 该店铺的店铺评级
+ 该店铺收藏数
+ 该店铺中有销量的商品数
+ 该店铺在整个市场中的排名
+ 该品类中有销量的商品数
+ 该品类在同品类市场中的排名
+ 店铺商品的销售均价
+ 店铺商品销售均价的排名
+ 商品描述产生的标签(one-hot)

1.2. 尝试过的算法:

+ LASSO
+ Decision Tree
+ Random Forest
+ Neural Network

1.3. 训练数据:

+ 按时间、平台活动(比如双11)、价格抽取其中的部分商品, 不作人工标注

1.4. 目标函数:

+ R方
+ MAE

1.5. 模型颗粒:

+ 商品的品类
+ 月份
+ 是否是活动

2.1. 相似商品分类是一个分类模型, 涉及特征有:

+ 两个商品之间词向量间的各种距离(cosine, cityblock, euclidean, chebyshev, canberra, braycurtis)

2.2. 包含的算法(ensemble learning):

+ Random Forest
+ Gradient Boosting
+ Logistic Regression
+ K Neighbors
+ Ada Boost
+ Naive Bayes
+ SVM
+ XGBoost

2.3. 训练数据:

+ 商品两两之间做人工标注, 记录相似程度

2.4. 目标函数:

+ Precision
+ Recall

2.5. 模型颗粒:

+ 商品的品类

二、资源:

1. 团队技能

+ python
+ 机器学习

2. 计算资源

+ CDH 5.7 4个节点

三、时间:

1. 一个月时间用于研究如何将实验室的研究结果应用到实际环境中去。

背景交代到这, 一个典型的难、穷、急的项目。 难点在于这些算法都是在单机上对样本数据进行处理(单进程 + 几万条数据)。
实际的数据, 商品基数就有5000多万, 两两组合后的数量更是夸张。 <br>

为此, 我制定的策略就是减少计算量和计算时间, 可以接受准确率的降低。首先就通过hive做了etl的脚本, 尽可能将原始数据都处理成特征数据(算法给的代码当中是直接对原始数据进行处理的)<br>

在回归模型中, 准确率最高的是神经网络, 但是是用python的sklearn实现的, 速度慢, 占用内存高, 无法分布式。
我先测试了一下几种算法的R2和MAE, 画出了拟合结果的分布图, 发现其中神经网络效果最好, 随机森林次之, R方都超过了0.95。 于是先对神经网络做了研究。
流行的框架中, tensorflow和pytorch都可以做分布式神经网络, 可惜环境并不支持用tensorflow on spark(centos 6 + python2), pytorch占用资源过大, 只好放弃。
转而研究随机森林, sklearn的多进程模式也不适合, 因为从hive中取数据是一件相对麻烦的事情, 最终用了单进程模式下的随机森林 + hive的UDF实现。
用随机森林的优势很明显, 训练速度快, 缺点是生成的模型非常巨大, 预测也比较慢。 模型大会导致载入后超过hive的预设参数(hive on spark的exector memory。
为此, 我进一步缩小了训练数据的选取范围, 虽然会导致更严重的过拟合, 但是相比炸Executor的风险, 这个是值得的。我知道有更好的办法可以解决这些问题,
比如升级一下python环境, 用tensorflow读取hdfs数据, 但是时间上并不允许(会影响现有的业务, 原有的用python2写的其它udf), 资源上也没有多余的机器可以做实验。
训练出来的模型以二进制的格式存放在PostgreSQL数据库中, 预测的时候用UDF获取到模型之后可以直接计算。需要处理的模型总数量特别多, 只要用了这个办法后, 我甚至可以同时在Mac上训练、Hadoop上预测, 可以充分利用各项资源。<br>

在分类模型中, XGBoost被我删除了, 原因在于会导致环境过于复杂。Keep it simple。由于训练数据过少(需要人工标注), 所以也可以单机训练, 分布式的预测。这个需求也一并解决了。<br>

其实很多工作原本都是属于算法团队的, 结果我在开发BI之余顺手介入了一些算法的内容, 本身就不是太合理, 对此, 我做一些总结, 也可以算作是教训啦:

1. 如果分工比较精细的话, 还是需要让算法今早接触真实数据, 对于同一个问题, 量变会引起质变, 不同的数据量实际上是不同的问题, 用到的方案也是不同的, 尽早知道数据量会减少选型上时间的浪费。
2. 不要花太多的时间纠结在到底用哪个算法更合适, 除非是追求超高准确率的应用, 否则算法之间导致的误差并不是很大。 特征工程更为重要, 好的特征对结果的影响是巨大的。
3. 不要执着于最新技术、最热技术, 选取已成熟的技术会更节省时间

最后祝各位项目顺利, 想看上面所说的代码, 可以移步到[Github](https://github.com/mpdevs/mplib)查看